<!DOCTYPE html>

</html>
<script type="text/javascript" src="https://livejs.com/live.js"></script>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.12.0/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-automl@1.3.0/dist/tf-automl.min.js"></script>
<script src='https://unpkg.com/tesseract.js@2.1.4/dist/tesseract.min.js'></script>
<!-- CSS only -->
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-gH2yIJqKdNHPEq0n4Mqa/HGKIhSkIHeL5AyhkYV8i59U5AR6csBvApHHNl/vI1Bx" crossorigin="anonymous">
<style>
 
thead{
    font-size: 30px;
}

h3.license{
    font-size: 16px;
    line-height: 30px;
}

mark{
    font-size:25px;
    line-height: 30px;
}

.tesseract{
    font-size:15px;
}

</style>
 
<table>
    <thead>
        <tr>
          <th scope="col">Original Image</th>
          <th scope="col">License Plate Detected</th> 
        </tr>
      </thead>
    
    <tr>
        <td> 
<img id="license-plate-image"  crossorigin="anonymous" src="http://raspberrypi.local/alpr/images/Cars1.png">

</td>

<!-- 
    <canvas width="450" height="600" id="canvas"></canvas>
  -->

<td> 
<canvas   id="canvas"></canvas>
</td>
</tr>


<tr>
    <th scope="row"><h2>Google Vision</h2></th></th>
    <td><h3 class="license">E 220<br>538<br><mark>PG MN112</mark><br>COI<br></h3></td>
  </tr>

  <tr>
    <th scope="row"><h2>Tesseract JS OCR</h2></th></th>
    <td><h3 class="tesseract"></h3></td>
  </tr>

</table>
 




<script>

    function log(a) {
        document.querySelector("pre").append("\n\n" + a)
    }

    async function run() {


        // Localize the License Plate Model
        const model = await tf.automl.loadObjectDetection('http://raspberrypi.local/alpr/model/model.json');
        const img = document.getElementById('license-plate-image');
        const options = {
            score: 0.5,
            iou: 0.5,
            topk: 20 //returns the k largest elements of the given input tensor along a given dimension
        };
        const predictions = await model.detect(img, options);
        // console.log(predictions);

        // Show the resulting object on the page.
        //const pre = document.createElement('pre');
        // pre.textContent = JSON.stringify(predictions, null, 2);
        // document.body.append(pre);

        var img3 = document.getElementById('license-plate-image');
        var width = img3.clientWidth;
        var height = img3.clientHeight;

        //log("Width: " + width);
        //log("Height: " + height);

        var c = document.getElementById("canvas");
        var ctx = c.getContext("2d");
        ctx.canvas.width = width;
        ctx.canvas.height = height;

        var img3 = document.getElementById("license-plate-image");

        /*
        ctx.drawImage(img3, 0, 0, width, height);
        // var canvas = document.getElementById('canvas');
        //  var context = canvas.getContext('2d');

        ctx.beginPath();
        ctx.rect(predictions[0].box.left, predictions[0].box.top, predictions[0].box.width, predictions[0].box
            .height);
        ctx.fillStyle = "rgba(255, 255, 255, 0.3)";
        ctx.fill();
        ctx.lineWidth = 4;
        ctx.strokeStyle = 'blue';
        ctx.stroke();
*/

//check the predictions array and the previous element are truthy
if(!!predictions && !!predictions[0] ){
    
        var left = predictions[0].box.left - 15;
        var top = predictions[0].box.top - 15;
        var width = predictions[0].box.width + 35;
        var height = predictions[0].box.height + 35;

        ctx.drawImage(img3, left, top, width, height, left, top, width, height);

}
        const exampleImage = 'http://raspberrypi.local:8080/images/realtime.jpg';


        //create tesseract worker
        const worker = Tesseract.createWorker({
            logger: m => console.log(m)
        });
        Tesseract.setLogging(true);
        work();

        async function work() {
            await worker.load();
            await worker.loadLanguage('eng'); //loads english lang model
            await worker.initialize('eng');
            await worker.setParameters({
                tessedit_pageseg_mode: 13, //set psm for 13 for OCR process
            });


            var img = c.toDataURL("image/png");

           
            // take cropped
             result = await worker.recognize(img);


           console.log(result);

            document.querySelector(".tesseract").innerHTML = JSON.stringify(result.data.text, null, 2);
 
            await worker.terminate();

        }
    }
    run();
</script>